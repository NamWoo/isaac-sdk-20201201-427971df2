{
  "inference_behavior": {
    "SelectorBehavior": {
      "desired_behavior": "tensorrt"
    }
  },
  "color_camera_encoder": {
    "ColorCameraEncoderCpu": {
      "rows": 256,
      "cols": 512
    }
  },
  "tensor_reshape_after_image_encoder": {
    "TensorReshape": {
      "output_tensor_dimensions": [1, 3, 256, 512]
    }
  },
  "tensor_rt_inference": {
    "TensorRTInference": {
      "model_file_path": "external/path_segmentation_pretrained_models/multiclass_warehouse_model.onnx",
      "engine_file_path": "/tmp/multiclass_warehouse_model.plan",
      "inference_mode": "Float16",
      "max_workspace_size": 67108864,
      "input_tensor_info": [
        {
          "operation_name": "input:0",
          "channel": "input",
          "dims": [1, 3, 256, 512]
        }
      ],
      "output_tensor_info": [
        {
          "operation_name": "prediction/truediv:0",
          "channel": "output",
          "dims": [1, 256, 512, 6]
        }
      ]
    }
  },
  "viewer": {
    "RawSegmentationViewer": {
      "tile_columns": 3
    },
    "DiscreteSegmentationViewer": {
      "range": [-1.0, 5.0]
    }
  },
  "tensor_reshape_before_segmentation_decoder": {
    "TensorReshape": {
      "output_tensor_dimensions": [256, 512, 6]
    }
  }
}
